from utils.new_obs_opt import state_summary
from utils.text_utils import parse_action_thinking

class treeNode(object):
    def __init__(self, action, parent=None, depth=0) -> None:
        """
            构建一个节点需要知道节点的action(Policy model), 以及action之后的下一个状态(World model)
        """
        self.trace = ''                     # str, trace, a set of `raw_action`
        self.action = action                        # str, execute action generated by the Policy model
        self.state = None                                # str, generated by the World model
        self.parent = parent                 # treeNode
        self.numVisits = 0                               # int, visiting frequency
        self.V = 0                                       # float, value of node, generated by the World model
        self.V_desc = ''                    # string, the detailed reasons generated by the reward model
        self.children: dict = {}                         # dict[str: treeNode], set of child node
        self.depth = depth                          # int, tree depth
        self.isFullyExpanded = False                     # expanded, whether has childnode
        self.isTerminal = False                          # value acceptable, whether task finished
        self.reflection = ''                # string 节点当前的状态反思，//#! 通过请求reflection LLM得到一个response
    
    # 当前节点下扩展子节点
    def append_children(self, action):
        node = treeNode(action, self, self.depth+1)
        node.update_trace_from_parent()
        self.children.update({action: node})
    
    # 当前节点下更新轨迹
    def update_trace_from_parent(self):
        """
            新的策略是继承父节点的轨迹，同时对父节点的状态进行压缩，提取作为当前节点的轨迹
            "trace_template": <step-{index}>\n{step_trace}\n</step-{index}>\n 
            "step_template": OBSERVATION:\n{observation}\nREASON FOR ACTION:\n{reason}\nACTION:\n{action}
        """
        
        # 继承父节点的轨迹
        if self.parent:
            self.trace = self.parent.trace
        else:
            self.trace = ""
            
        # 解析action获取reason和action（占位函数）
        thinking, step_action = parse_action_thinking(self.action)
        
        # 对当前节点状态进行压缩，提取观察信息（占位函数）
        obs_summary = state_summary(
            item={'state': self.parent.state, 'output': step_action}, 
            sample_strategy='nearest'
        )
        
        # 生成当前步骤的轨迹片段
        step_index = self.depth  # 使用节点深度作为步骤索引
        step_trace = f"OBSERVATION:\n{obs_summary}\nREASON FOR ACTION:\n{thinking}\nACTION:\n{step_action}"
        current_step = f"<step-{step_index}>\n{step_trace}\n</step-{step_index}>\n"
        
        # 将当前步骤添加到轨迹中
        self.trace += current_step
        
    # 更新节点价值
    def update_value(self, value, V_desc):
        self.V = value
        self.V_desc = V_desc
    # 更新节点状态
    def update_state(self, state):
        self.state = state
    
    # 更新节点反馈
    def update_reflection(self, reflection):
        self.reflection = reflection
    
    def getBestV(self):  # Gets the subtree maximum value node
        if not self.isFullyExpanded:
            return self, self.V
        max_V = self.V
        max_node = self
        for child in self.children.values():
            subNode, subValue = child.getBestV()
            if subValue >= max_V:
                max_V = subValue
                max_node = subNode
        return max_node, max_V
    